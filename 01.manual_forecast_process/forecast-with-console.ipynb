{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household energy consumption forecast\n",
    "#### *- Leveraging Amazon Forecast UI Console -*\n",
    "---\n",
    "\n",
    "Previously, we leveraged the Amazon Forecast console to predict household energy consumption. We are now going to leverage the high level APIs from this service to achieve the same: **this notebook takes approximately an hour to run.**\n",
    "\n",
    "The overall process for using Amazon Forecast is the following:\n",
    "\n",
    "1. Create a **Dataset Group**, this is the large box that isolates models and the data they are trained on from each other. You can see that as an independant forecasting \"project\".\n",
    "1. Create a **Dataset**: in Forecast there are 3 types of dataset, *Target Time Series*, *Related Time Series*, and *Item Metadata*. The *Target Time Series* is required, the others provide additional context that certain algorithms can leverage.\n",
    "1. **Import data**, this moves the information from S3 into a storage volume where the data can be used for training and validation. You can see this as the ingestion process into the Forecast dataset.\n",
    "1. **Train a model**, Forecast automates this process for you but you can also select particular algorithms, and you can provide your own hyper parameters or use Hyper Parameter Optimization (HPO) to determine the most performant values for your data.\n",
    "1. **Deploy a Predictor**, here you are deploying your model so you can use it to generate a forecast.\n",
    "1. **Query the Forecast**, given a request bounded by time for an item, return the forecast for it. Once you have this you can evaluate its performance or use it to guide your decisions about the future.\n",
    "\n",
    "In this notebook we will be walking through the first 3 steps outlined above. One additional task that will be done here is to trim part of our training and validation data so that we can measure the accuracy of a forecast against our predictions.\n",
    "\n",
    "## Table Of Contents\n",
    "* **Preparation:**\n",
    "  * Setup\n",
    "  * Data Preparation\n",
    "  * Creating the Dataset Group and Dataset\n",
    "* **Building a predictor:**\n",
    "  * Create a Predictor\n",
    "  * Deploy a Predictor\n",
    "  * Obtain a Forecast\n",
    "* **Evaluating your forecast:** now is the time to pull down the predictions from this Predictor, and compare them to the actual observed values:\n",
    "  * Obtaining a Prediction\n",
    "  * Plotting the Actual Results\n",
    "  * Plotting the Prediction\n",
    "  * Comparing the Prediction to Actual Results\n",
    "* **Cleanup:** after building completing the notebooks you may want to delete the following to prevent any unwanted charges:\n",
    "  * Forecasts\n",
    "  * Predictors\n",
    "  * Datasets\n",
    "  * Dataset Groups\n",
    "\n",
    "For more informations about Amazon Forecast APIs, please check the [documentation](https://docs.aws.amazon.com/forecast/latest/dg/what-is-forecast.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 01\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will be referred in console operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 02\n",
    "\n",
    "BUCKET = sagemaker.Session().default_bucket()\n",
    "PREFIX = 'forecast-workshop'\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "print(f\"Bucket Name: {BUCKET}\")\n",
    "print(f\"IAM role: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
